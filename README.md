


프로젝트 설계
--------------------------------------------------------------------------------------------------------------------------------------------


커뮤니티 서버 : 사용자가 게시물과 댓글을 작성
관리자 서버와 RabbitMQ를 통해 연결
관리자 서버 : 금지어를 관리하고 외부 API 또는 다른 팀의 AI를 통해서 욕설을 탐지
커뮤니티 서버와 RabbitMQ로 연결되있고 욕설 탐지 서버와 gRPC로 연결


욕설 처리 로직 구현
--------------------------------------------------------------------------------------------------------------------------------------------

 게시물 작성시 Queue에 넣어두고 최대한 빠르게 is_visible을 false로 처리해서 사용자에게 보여주지 않는 방식


아키텍처
--------------------------------------------------------------------------------------------------------------------------------------------



<img width="822" height="170" alt="image" src="https://github.com/user-attachments/assets/fdc91ec0-8335-4bac-98c3-ab6f74c96a3b" />


grpc
--------------------------------------------------------------------------------------------------------------------------------------------


gRPC 통신을 사용한 이유는 다음과 같습니다.

욕설 검증 서버에서 커뮤니티 서버의 데이터베이스에 대한 접근 권한이 없는 상황일 수 있습니다.
욕설 검증 서버 자체로도 이미 부하가 충분히 높을 텐데 게시물 블라인드 처리라는 또 다른 부하를 주고 싶지 않았습니다.
또한 욕설 검증이라는 역할에도 맞지 않는 것 같습니다.
양쪽의 처리량 차이로 인해서 관리자 서버에서 에러가 발생할 경우 nack를 보내서 queue에 다시 넣어주는 방식으로 누락을 방지


Trouble shooting
--------------------------------------------------------------------------------------------------------------------------------------------
k6로 부하테스트를하니 

현재 구축한 시스템은 입구(커뮤니티 서버)와 엔진(욕설 탐지 서버) 모두 초당 500건 이상의 요청을 10ms 이내에 처리할 수 있습니다. 

이 데이터를 기반으로 "1,000명의 동시 접속자가 초당 500건 이상의 게시물을 작성하는 환경에서도, 비동기 메시징을 통해 평균 2.64ms 이내의 응답 속도를 유지함"

하지만 이건 금지단어가 3개였을 경우고 금지단어가 10만개일경우 `http_req_failed` 에러율이 급증함을 확인했습니다.

로그를 확인해보니 Connection Pool 고갈 문제였습니다.

추가적으로 

✗ response time < 100ms` (0% 성공)
단 하나의 요청도 100ms 안에 들어오지 못했습니다. 가장 빠른 응답(min)조차 281ms였음. 시스템으로서의 가치가 거의 상실된 상태였음을 확인했습니다.

 왜 이렇게 느렸을까?
 
 `WHERE :text ~ word` 쿼리 때문. 1,000명의 유저가 동시에 "이 문장에 욕설이 있니?"라고 물어볼 때마다 DB는 10만 개의 정규식을 하나하나 대조. CPU 연산량이 기하급수적으로 늘어나면서 DB 서버가 거의 마비되었던 것이였습니다.


해결
--------------------------------------------------------------------------------------------------------------------------------------------

로컬 캐싱 전략: 매 요청마다 DB와 통신하는 I/O 비용을 제거하기 위해, 서버 기동 시 10만 개의 금지어를 메모리에 상주시켜 DB 의존성 원천 차단.

알고리즘 최적화: 다중 패턴 매칭 알고리즘인 Aho-Corasick 적용 ->  금지어 개수와 상관없이 문장을 단 한 번만 훑는O(N) 구조로 개선.



| **지표** | **최적화 전 (DB Index 방식)** | **최적화 후 (Aho-Corasick)** | **개선 결과** |
| --- | --- | --- | --- |
| **평균 응답 시간 (Avg)** | **10.11s** (10,110ms) | **1.17ms ~ 4.67ms** | **약 8,000배 이상 단축** |
| **p(95) 응답 시간** | **18.13s** | **8ms** | **안정성 대폭 향상** |
| **처리량 (Throughput)** | **25.5 RPS** | **537 RPS** | **처리 능력 21배 증가** |
| **에러율 (Failures)** | **33.33%** | **0.00%** | **성공률 100% 달성** |


결론
--------------------------------------------------------------------------------------------------------------------------------------------

1 인덱스 활용의 재정의: 단순히 인덱스를 생성하는 것보다 쿼리의 방향과 데이터 접근 구조가 인덱스 원리에 적합한지 판단하는 것이 중요햇습니다.

2 고가용성 확보: 가상 유저를 1,000명까지 늘린 5분간의 시스템 테스트에서도 성능 저하 없이 확장성 확인.

3 시스템 밸런싱: 커뮤니티 서버의 메시지 생산 속도와 탐지 서버의 처리 속도를 동기화하여 RabbitMQ 큐의 적체 현상 방지




